#!/usr/bin/env python3
"""
æ•°æ®å¤„ç†æµ‹è¯•è„šæœ¬
æµ‹è¯•æ•°æ®é¢„å¤„ç†å’Œåˆ†æçš„å„ä¸ªç¯èŠ‚
"""

import pandas as pd
import json
from data_preprocessor import XiaoXinBaoDataProcessor
from monthly_analyzer import MonthlyAnalyzer, convert_numpy_types

def test_data_loading():
    """æµ‹è¯•æ•°æ®åŠ è½½"""
    print("=== æµ‹è¯•æ•°æ®åŠ è½½ ===")
    processor = XiaoXinBaoDataProcessor("input/filtered_data.csv")
    
    if processor.load_data():
        print(f"âœ“ æ•°æ®åŠ è½½æˆåŠŸ: {processor.df.shape}")
        print(f"åŸå§‹åˆ—å: {processor.df.columns.tolist()}")
        return processor
    else:
        print("âœ— æ•°æ®åŠ è½½å¤±è´¥")
        return None

def test_column_cleaning(processor):
    """æµ‹è¯•åˆ—åæ¸…ç†"""
    print("\n=== æµ‹è¯•åˆ—åæ¸…ç† ===")
    try:
        cleaned_columns = processor.clean_column_names()
        print(f"âœ“ åˆ—åæ¸…ç†æˆåŠŸ: {cleaned_columns}")
        return True
    except Exception as e:
        print(f"âœ— åˆ—åæ¸…ç†å¤±è´¥: {e}")
        return False

def test_timestamp_parsing(processor):
    """æµ‹è¯•æ—¶é—´æˆ³è§£æ"""
    print("\n=== æµ‹è¯•æ—¶é—´æˆ³è§£æ ===")
    try:
        valid_count = processor.parse_timestamp()
        print(f"âœ“ æ—¶é—´æˆ³è§£ææˆåŠŸ: {valid_count}/{len(processor.df)}")
        
        # æ˜¾ç¤ºæ—¶é—´èŒƒå›´
        if 'timestamp' in processor.df.columns:
            min_time = processor.df['timestamp'].min()
            max_time = processor.df['timestamp'].max()
            print(f"æ—¶é—´èŒƒå›´: {min_time} åˆ° {max_time}")
        
        return True
    except Exception as e:
        print(f"âœ— æ—¶é—´æˆ³è§£æå¤±è´¥: {e}")
        return False

def test_dialogue_extraction(processor):
    """æµ‹è¯•å¯¹è¯å†…å®¹æå–"""
    print("\n=== æµ‹è¯•å¯¹è¯å†…å®¹æå– ===")
    try:
        avg_length = processor.extract_dialogue_content()
        print(f"âœ“ å¯¹è¯å†…å®¹æå–æˆåŠŸï¼Œå¹³å‡é•¿åº¦: {avg_length:.2f}")
        
        # æ£€æŸ¥æå–è´¨é‡
        if 'clean_dialogue' in processor.df.columns:
            non_empty = processor.df['clean_dialogue'].str.len() > 0
            print(f"éç©ºå¯¹è¯æ¯”ä¾‹: {non_empty.sum()}/{len(processor.df)} ({non_empty.mean()*100:.1f}%)")
        
        return True
    except Exception as e:
        print(f"âœ— å¯¹è¯å†…å®¹æå–å¤±è´¥: {e}")
        return False

def test_user_classification(processor):
    """æµ‹è¯•ç”¨æˆ·åˆ†ç±»"""
    print("\n=== æµ‹è¯•ç”¨æˆ·åˆ†ç±» ===")
    try:
        user_dist = processor.categorize_users()
        print(f"âœ“ ç”¨æˆ·åˆ†ç±»æˆåŠŸ: {user_dist}")
        return True
    except Exception as e:
        print(f"âœ— ç”¨æˆ·åˆ†ç±»å¤±è´¥: {e}")
        return False

def test_sentiment_analysis(processor):
    """æµ‹è¯•æƒ…æ„Ÿåˆ†æ"""
    print("\n=== æµ‹è¯•æƒ…æ„Ÿåˆ†æ ===")
    try:
        sentiment_dist = processor.analyze_sentiment()
        print(f"âœ“ æƒ…æ„Ÿåˆ†ææˆåŠŸ: {sentiment_dist}")
        return True
    except Exception as e:
        print(f"âœ— æƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")
        return False

def test_monthly_split(processor):
    """æµ‹è¯•æœˆåº¦æ•°æ®åˆ†å‰²"""
    print("\n=== æµ‹è¯•æœˆåº¦æ•°æ®åˆ†å‰² ===")
    try:
        monthly_data = processor.split_by_month()
        print(f"âœ“ æœˆåº¦åˆ†å‰²æˆåŠŸ: {len(monthly_data)} ä¸ªæœˆ")
        for month, data in monthly_data.items():
            print(f"  {month}: {len(data)} æ¡è®°å½•")
        return monthly_data
    except Exception as e:
        print(f"âœ— æœˆåº¦åˆ†å‰²å¤±è´¥: {e}")
        return None

def test_monthly_analysis(monthly_data):
    """æµ‹è¯•æœˆåº¦åˆ†æ"""
    print("\n=== æµ‹è¯•æœˆåº¦åˆ†æ ===")
    
    if not monthly_data:
        print("âœ— æ— æœˆåº¦æ•°æ®å¯ä¾›åˆ†æ")
        return False
    
    success_count = 0
    for month, data in monthly_data.items():
        try:
            print(f"\nåˆ†ææœˆä»½: {month}")
            analyzer = MonthlyAnalyzer(data)
            report = analyzer.comprehensive_analysis()
            
            # æµ‹è¯•JSONåºåˆ—åŒ–
            json_str = json.dumps(report, ensure_ascii=False, indent=2)
            print(f"âœ“ {month} åˆ†ææˆåŠŸï¼ŒJSONé•¿åº¦: {len(json_str)}")
            
            # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
            metrics = report.get('basic_metrics', {})
            print(f"  å¯¹è¯æ•°: {metrics.get('total_dialogues', 0)}")
            print(f"  å¹³å‡é•¿åº¦: {metrics.get('avg_dialogue_length', 0):.1f}")
            
            success_count += 1
        except Exception as e:
            print(f"âœ— {month} åˆ†æå¤±è´¥: {e}")
    
    print(f"\næœˆåº¦åˆ†ææ€»ç»“: {success_count}/{len(monthly_data)} æˆåŠŸ")
    return success_count > 0

def test_json_serialization():
    """æµ‹è¯•JSONåºåˆ—åŒ–åŠŸèƒ½"""
    print("\n=== æµ‹è¯•JSONåºåˆ—åŒ– ===")
    
    import numpy as np
    
    # æµ‹è¯•æ•°æ®
    test_data = {
        'int64_value': np.int64(42),
        'float64_value': np.float64(3.14),
        'array_value': np.array([1, 2, 3]),
        'nested_dict': {
            'inner_int': np.int64(100),
            'inner_list': [np.int64(1), np.int64(2)]
        }
    }
    
    try:
        converted = convert_numpy_types(test_data)
        json_str = json.dumps(converted)
        print("âœ“ JSONåºåˆ—åŒ–æˆåŠŸ")
        print(f"è½¬æ¢ç»“æœ: {converted}")
        return True
    except Exception as e:
        print(f"âœ— JSONåºåˆ—åŒ–å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹æ•°æ®å¤„ç†æµ‹è¯•\n")
    
    # æµ‹è¯•åºåˆ—
    tests_passed = 0
    total_tests = 0
    
    # 1. æ•°æ®åŠ è½½
    total_tests += 1
    processor = test_data_loading()
    if processor:
        tests_passed += 1
    else:
        print("æ•°æ®åŠ è½½å¤±è´¥ï¼Œç»ˆæ­¢æµ‹è¯•")
        return
    
    # 2. åˆ—åæ¸…ç†
    total_tests += 1
    if test_column_cleaning(processor):
        tests_passed += 1
    
    # 3. æ—¶é—´æˆ³è§£æ
    total_tests += 1
    if test_timestamp_parsing(processor):
        tests_passed += 1
    
    # 4. å¯¹è¯å†…å®¹æå–
    total_tests += 1
    if test_dialogue_extraction(processor):
        tests_passed += 1
    
    # 5. ç”¨æˆ·åˆ†ç±»
    total_tests += 1
    if test_user_classification(processor):
        tests_passed += 1
    
    # 6. æƒ…æ„Ÿåˆ†æ
    total_tests += 1
    if test_sentiment_analysis(processor):
        tests_passed += 1
    
    # 7. æœˆåº¦åˆ†å‰²
    total_tests += 1
    monthly_data = test_monthly_split(processor)
    if monthly_data:
        tests_passed += 1
    
    # 8. æœˆåº¦åˆ†æ
    total_tests += 1
    if test_monthly_analysis(monthly_data):
        tests_passed += 1
    
    # 9. JSONåºåˆ—åŒ–
    total_tests += 1
    if test_json_serialization():
        tests_passed += 1
    
    # æ€»ç»“
    print(f"\n=== æµ‹è¯•æ€»ç»“ ===")
    print(f"é€šè¿‡: {tests_passed}/{total_tests}")
    print(f"æˆåŠŸç‡: {tests_passed/total_tests*100:.1f}%")
    
    if tests_passed == total_tests:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ•°æ®å¤„ç†ç®¡é“æ­£å¸¸å·¥ä½œã€‚")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¿®å¤ã€‚")

if __name__ == "__main__":
    main()
