#!/usr/bin/env python3
"""
å°é¦¨å®è¿è¥åˆ†æ - å•å…ƒæµ‹è¯•æ¨¡å—
æµ‹è¯•å„ä¸ªç»„ä»¶çš„åŠŸèƒ½å’Œè¾¹ç•Œæƒ…å†µ
"""

import unittest
import pandas as pd
import json
import tempfile
import os
from io import StringIO
from data_preprocessor import XiaoXinBaoDataProcessor
from monthly_analyzer import MonthlyAnalyzer, convert_numpy_types
import numpy as np

class TestDataPreprocessor(unittest.TestCase):
    """æµ‹è¯•æ•°æ®é¢„å¤„ç†å™¨"""
    
    def setUp(self):
        """è®¾ç½®æµ‹è¯•æ•°æ®"""
        # åˆ›å»ºæµ‹è¯•CSVæ•°æ®
        self.test_csv_content = """æ—¶é—´,æ¥æº,ä½¿ç”¨è€…,è”ç³»æ–¹å¼,æ ‡é¢˜,æ¶ˆæ¯æ€»æ•°,ç”¨æˆ·èµåŒåé¦ˆ,ç”¨æˆ·åå¯¹åé¦ˆ,è‡ªå®šä¹‰åé¦ˆ,æ ‡æ³¨ç­”æ¡ˆ,å¯¹è¯è¯¦æƒ…
2025/7/28 14:32,å¤–éƒ¨æ¥å…¥å•ç‚¹,shareChat-123,'-,æµ‹è¯•æ ‡é¢˜,4,[],[],[],[],"[{""type"":""text"",""text"":{""content"":""æ‚¨å¥½ï¼Œæˆ‘æ˜¯æ‚£è€…å®¶å±ï¼Œéœ€è¦å¸®åŠ©""}}]"
2025/7/29 15:30,å¤–éƒ¨æ¥å…¥å•ç‚¹,shareChat-456,'-,å’¨è¯¢é—®é¢˜,6,[],[],[],[],"[{""type"":""text"",""text"":{""content"":""æˆ‘æ„Ÿåˆ°å¾ˆæ‹…å¿ƒå’Œç„¦è™‘ï¼ŒåŒ–ç–—å¾ˆç—›è‹¦""}}]"
2025/7/30 10:15,å¤–éƒ¨æ¥å…¥å•ç‚¹,shareChat-789,'-,å¿—æ„¿è€…å’¨è¯¢,3,[],[],[],[],"[{""type"":""text"",""text"":{""content"":""æˆ‘æ˜¯å¿—æ„¿è€…ï¼Œæƒ³å¸®åŠ©æ‚£è€…""}}]"
"""
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        self.temp_file = tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False, encoding='utf-8')
        self.temp_file.write(self.test_csv_content)
        self.temp_file.close()
        
        self.processor = XiaoXinBaoDataProcessor(self.temp_file.name)
    
    def tearDown(self):
        """æ¸…ç†æµ‹è¯•æ•°æ®"""
        os.unlink(self.temp_file.name)
    
    def test_load_data(self):
        """æµ‹è¯•æ•°æ®åŠ è½½"""
        result = self.processor.load_data()
        self.assertTrue(result)
        self.assertEqual(len(self.processor.df), 3)
        self.assertEqual(len(self.processor.df.columns), 11)
    
    def test_clean_column_names(self):
        """æµ‹è¯•åˆ—åæ¸…ç†"""
        self.processor.load_data()
        cleaned_columns = self.processor.clean_column_names()
        
        # æ£€æŸ¥æ ‡å‡†åŒ–åˆ—å
        expected_columns = ['timestamp', 'source', 'user_id', 'contact_type', 'title', 
                          'message_type', 'user_agreement', 'user_reply', 'auto_reply', 
                          'notes', 'dialogue_content']
        self.assertEqual(cleaned_columns, expected_columns)
    
    def test_parse_timestamp(self):
        """æµ‹è¯•æ—¶é—´æˆ³è§£æ"""
        self.processor.load_data()
        self.processor.clean_column_names()
        valid_count = self.processor.parse_timestamp()
        
        self.assertEqual(valid_count, 3)
        self.assertIn('timestamp', self.processor.df.columns)
        self.assertIn('year_month', self.processor.df.columns)
    
    def test_extract_dialogue_content(self):
        """æµ‹è¯•å¯¹è¯å†…å®¹æå–"""
        self.processor.load_data()
        self.processor.clean_column_names()
        avg_length = self.processor.extract_dialogue_content()
        
        self.assertGreater(avg_length, 0)
        self.assertIn('clean_dialogue', self.processor.df.columns)
        
        # æ£€æŸ¥å†…å®¹æå–è´¨é‡
        dialogues = self.processor.df['clean_dialogue'].tolist()
        self.assertIn('æ‚¨å¥½', dialogues[0])
        self.assertIn('æ‹…å¿ƒ', dialogues[1])
        self.assertIn('å¿—æ„¿è€…', dialogues[2])
    
    def test_categorize_users(self):
        """æµ‹è¯•ç”¨æˆ·åˆ†ç±»"""
        self.processor.load_data()
        self.processor.clean_column_names()
        self.processor.extract_dialogue_content()
        user_dist = self.processor.categorize_users()
        
        self.assertIn('user_type', self.processor.df.columns)
        self.assertIn('volunteer', user_dist)
        self.assertIn('patient_family', user_dist)
    
    def test_analyze_sentiment(self):
        """æµ‹è¯•æƒ…æ„Ÿåˆ†æ"""
        self.processor.load_data()
        self.processor.clean_column_names()
        self.processor.extract_dialogue_content()
        sentiment_dist = self.processor.analyze_sentiment()
        
        self.assertIn('sentiment', self.processor.df.columns)
        self.assertIn('negative', sentiment_dist)  # "æ‹…å¿ƒå’Œç„¦è™‘"åº”è¯¥è¢«è¯†åˆ«ä¸ºè´Ÿé¢
        self.assertIn('positive', sentiment_dist)   # "å¸®åŠ©"åº”è¯¥è¢«è¯†åˆ«ä¸ºæ­£é¢

class TestMonthlyAnalyzer(unittest.TestCase):
    """æµ‹è¯•æœˆåº¦åˆ†æå™¨"""
    
    def setUp(self):
        """è®¾ç½®æµ‹è¯•æ•°æ®"""
        # åˆ›å»ºæµ‹è¯•DataFrame
        self.test_data = pd.DataFrame({
            'timestamp': pd.to_datetime(['2025-07-15 10:00', '2025-07-15 11:00', '2025-07-15 12:00']),
            'user_id': ['user1', 'user2', 'user1'],
            'clean_dialogue': [
                'æˆ‘å¾ˆæ‹…å¿ƒæ²»ç–—æ•ˆæœ',
                'è°¢è°¢åŒ»ç”Ÿçš„å¸®åŠ©',
                'ç—‡çŠ¶ç®¡ç†å¾ˆé‡è¦'
            ],
            'user_type': ['patient_family', 'patient_family', 'volunteer'],
            'sentiment': ['negative', 'positive', 'neutral'],
            'year_month': pd.Period('2025-07')
        })
        
        self.analyzer = MonthlyAnalyzer(self.test_data)
    
    def test_basic_metrics(self):
        """æµ‹è¯•åŸºç¡€æŒ‡æ ‡è®¡ç®—"""
        metrics = self.analyzer.basic_metrics()
        
        self.assertEqual(metrics['total_dialogues'], 3)
        self.assertEqual(metrics['unique_users'], 2)
        self.assertIsInstance(metrics['avg_dialogue_length'], float)
        self.assertIn('date_range', metrics)
    
    def test_conversation_analysis(self):
        """æµ‹è¯•å¯¹è¯ä¸»é¢˜åˆ†æ"""
        themes = self.analyzer.conversation_analysis()
        
        self.assertIsInstance(themes, dict)
        self.assertIn('symptom_management', themes)
        self.assertIn('emotional_support', themes)
        self.assertGreater(themes['symptom_management'], 0)  # "ç—‡çŠ¶ç®¡ç†"åº”è¯¥è¢«è¯†åˆ«
    
    def test_user_journey_analysis(self):
        """æµ‹è¯•ç”¨æˆ·æ—…ç¨‹åˆ†æ"""
        journey = self.analyzer.user_journey_analysis()
        
        self.assertIn('first_interaction_sentiment', journey)
        self.assertIn('last_interaction_sentiment', journey)
        self.assertIsInstance(journey['first_interaction_sentiment'], dict)
    
    def test_pain_points_identification(self):
        """æµ‹è¯•ç—›ç‚¹è¯†åˆ«"""
        pain_points = self.analyzer.pain_points_identification()
        
        self.assertIsInstance(pain_points, list)
        # æ¯ä¸ªç—›ç‚¹åº”è¯¥æœ‰æŒ‡å®šçš„ç»“æ„
        if pain_points:
            pain_point = pain_points[0]
            self.assertIn('indicator', pain_point)
            self.assertIn('count', pain_point)
            self.assertIn('examples', pain_point)
    
    def test_comprehensive_analysis(self):
        """æµ‹è¯•ç»¼åˆåˆ†æ"""
        report = self.analyzer.comprehensive_analysis()
        
        required_keys = ['month', 'basic_metrics', 'conversation_themes', 
                        'user_journey', 'pain_points', 'volunteer_effectiveness',
                        'insights', 'recommendations']
        
        for key in required_keys:
            self.assertIn(key, report)
        
        # æµ‹è¯•JSONåºåˆ—åŒ–
        try:
            json.dumps(report, ensure_ascii=False)
        except TypeError:
            self.fail("Report contains non-serializable data")

class TestConvertNumpyTypes(unittest.TestCase):
    """æµ‹è¯•numpyç±»å‹è½¬æ¢"""
    
    def test_convert_numpy_int(self):
        """æµ‹è¯•numpyæ•´æ•°è½¬æ¢"""
        result = convert_numpy_types(np.int64(42))
        self.assertEqual(result, 42)
        self.assertIsInstance(result, int)
    
    def test_convert_numpy_float(self):
        """æµ‹è¯•numpyæµ®ç‚¹æ•°è½¬æ¢"""
        result = convert_numpy_types(np.float64(3.14))
        self.assertEqual(result, 3.14)
        self.assertIsInstance(result, float)
    
    def test_convert_numpy_array(self):
        """æµ‹è¯•numpyæ•°ç»„è½¬æ¢"""
        result = convert_numpy_types(np.array([1, 2, 3]))
        self.assertEqual(result, [1, 2, 3])
        self.assertIsInstance(result, list)
    
    def test_convert_nested_dict(self):
        """æµ‹è¯•åµŒå¥—å­—å…¸è½¬æ¢"""
        test_data = {
            'int_val': np.int64(100),
            'float_val': np.float64(2.71),
            'nested': {
                'array_val': np.array([4, 5, 6]),
                'normal_val': 'text'
            }
        }
        
        result = convert_numpy_types(test_data)
        
        self.assertIsInstance(result['int_val'], int)
        self.assertIsInstance(result['float_val'], float)
        self.assertIsInstance(result['nested']['array_val'], list)
        self.assertEqual(result['nested']['normal_val'], 'text')

class TestEndToEnd(unittest.TestCase):
    """ç«¯åˆ°ç«¯æµ‹è¯•"""
    
    def test_full_pipeline(self):
        """æµ‹è¯•å®Œæ•´æ•°æ®å¤„ç†ç®¡é“"""
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_csv = """æ—¶é—´,æ¥æº,ä½¿ç”¨è€…,è”ç³»æ–¹å¼,æ ‡é¢˜,æ¶ˆæ¯æ€»æ•°,ç”¨æˆ·èµåŒåé¦ˆ,ç”¨æˆ·åå¯¹åé¦ˆ,è‡ªå®šä¹‰åé¦ˆ,æ ‡æ³¨ç­”æ¡ˆ,å¯¹è¯è¯¦æƒ…
2025/6/15 10:00,æµ‹è¯•,user1,'-,æµ‹è¯•,1,[],[],[],[],"[{""type"":""text"",""text"":{""content"":""æˆ‘æ˜¯ç™Œç—‡æ‚£è€…ï¼Œæ„Ÿåˆ°å¾ˆç„¦è™‘""}}]"
2025/7/15 11:00,æµ‹è¯•,user2,'-,æµ‹è¯•,1,[],[],[],[],"[{""type"":""text"",""text"":{""content"":""æˆ‘æ˜¯å¿—æ„¿è€…ï¼Œæƒ³è¦å¸®åŠ©åˆ«äºº""}}]"
2025/7/16 12:00,æµ‹è¯•,user3,'-,æµ‹è¯•,1,[],[],[],[],"[{""type"":""text"",""text"":{""content"":""è°¢è°¢åŒ»ç”Ÿçš„ä¸“ä¸šå»ºè®®""}}]"
"""
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        temp_file = tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False, encoding='utf-8')
        temp_file.write(test_csv)
        temp_file.close()
        
        try:
            # æ•°æ®é¢„å¤„ç†
            processor = XiaoXinBaoDataProcessor(temp_file.name)
            self.assertTrue(processor.load_data())
            
            processor.clean_column_names()
            processor.parse_timestamp()
            processor.extract_dialogue_content()
            processor.categorize_users()
            processor.analyze_sentiment()
            
            # æŒ‰æœˆåˆ†å‰²
            monthly_data = processor.split_by_month()
            self.assertGreater(len(monthly_data), 0)
            
            # æœˆåº¦åˆ†æ
            for month, data in monthly_data.items():
                analyzer = MonthlyAnalyzer(data)
                report = analyzer.comprehensive_analysis()
                
                # éªŒè¯æŠ¥å‘Šç»“æ„
                self.assertIn('month', report)
                self.assertIn('basic_metrics', report)
                
                # éªŒè¯JSONåºåˆ—åŒ–
                json_str = json.dumps(report, ensure_ascii=False)
                self.assertIsInstance(json_str, str)
                
        finally:
            os.unlink(temp_file.name)

def run_unit_tests():
    """è¿è¡Œæ‰€æœ‰å•å…ƒæµ‹è¯•"""
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()
    
    # æ·»åŠ æµ‹è¯•ç±»
    suite.addTests(loader.loadTestsFromTestCase(TestDataPreprocessor))
    suite.addTests(loader.loadTestsFromTestCase(TestMonthlyAnalyzer))
    suite.addTests(loader.loadTestsFromTestCase(TestConvertNumpyTypes))
    suite.addTests(loader.loadTestsFromTestCase(TestEndToEnd))
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    # è¿”å›æµ‹è¯•ç»“æœ
    return result.wasSuccessful()

if __name__ == '__main__':
    print("=== å°é¦¨å®è¿è¥åˆ†æ - å•å…ƒæµ‹è¯• ===\n")
    
    success = run_unit_tests()
    
    if success:
        print("\nğŸ‰ æ‰€æœ‰å•å…ƒæµ‹è¯•é€šè¿‡ï¼")
    else:
        print("\nâŒ éƒ¨åˆ†å•å…ƒæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç ã€‚")
