# ===============
# DeepSeek 配置示例
# ===============
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_BASE_URL=https://api.deepseek.com
DEEPSEEK_TIMEOUT_SEC=180

# =====================
# LMStudio 本地模型配置示例
# =====================
# 如果使用 LMStudio 本地 OpenAI 兼容端点，请配置以下变量
LMSTUDIO_BASE_URL=http://localhost:1234/v1
# LMStudio 中加载的模型名称，例如：deepseek-r1-distill-llama-8b@q8_0
LMSTUDIO_MODEL_NAME=deepseek-r1-distill-llama-8b@q8_0
# 本地服务通常不需要 API KEY，如果需要请填写
LMSTUDIO_API_KEY=1234
LMSTUDIO_TIMEOUT_SEC=180
# 本地模型上下文窗口限制（token数），用于分块处理
LMSTUDIO_MAX_TOKENS=4096
# 每块的最大输入token数（留出输出空间）
LMSTUDIO_CHUNK_SIZE=3000
